# RISC-V 操作系统内存管理与分页机制实现报告

## 1. 引言

### 1.1. 实验目标

本次实验旨在为一个基于 RISC-V 架构的最小化操作系统内核，构建一套基础且功能完备的内存管理系统。其核心目标分为两个层面：
1.  **物理内存管理**：实现一个页帧分配器（Page Frame Allocator），能够有效地管理和分配、回收以页（Page）为单位的物理内存。
2.  **虚拟内存**：基于 RISC-V Sv39 分页规范，建立一套虚拟内存系统，为内核提供独立且受保护的地址空间，并为未来支持用户进程打下坚实基础。

### 1.2. 技术背景

本系统采用 RISC-V 64位架构，其 Sv39 分页模式是核心。Sv39 提供了三级页表结构，能够将 64 位的虚拟地址映射到 56 位的物理地址。每个页表包含 512 个页表项（PTE），每个PTE大小为 8 字节，正好填满一个 4KB 的物理页。理解并正确利用这一硬件机制是实现虚拟内存的关键。

## 2. 核心组件实现

内存管理系统的实现主要围绕两大模块：物理内存分配器 (`kalloc.c`) 和页表管理器 (`vm.c`)。

### 2.1. 物理内存管理 (`kalloc.c`)

为了管理物理内存，我们选择了一种简单而高效的实现方式：**链表式空闲页管理**。

*   **数据结构**：我们没有使用额外的数据结构来追踪空闲页，而是巧妙地利用了空闲页自身。每个空闲页的前 8 个字节被强制转换为一个指向下一个空闲页的指针 (`struct run { struct run *next; };`)。
*   **`kinit()`**：在内核初始化阶段，`kinit()` 负责接管内核代码/数据段之后的所有物理内存。它以页为单位，将这些内存逐一添加到全局的 `freelist` 链表的头部，构建起最初的物理内存池。
*   **`kalloc()`**：当需要分配一个物理页时，`kalloc()` 从 `freelist` 头部取下一个节点，更新头指针，并将返回的页面清零（以避免数据泄露），然后返回其地址。
*   **`kfree()`**：当一个物理页被释放时，`kfree()` 将其重新链接到 `freelist` 的头部。

这个设计简洁明了，避免了复杂的位图或伙伴系统，非常适合在早期内核中使用。

### 2.2. 页表与虚拟内存管理 (`vm.c`)

这是内存管理的核心，所有与地址转换相关的逻辑都在这里实现。

#### 2.2.1. 核心函数 `walk()`

`walk()` 函数是整个页表系统的灵魂。它的核心职责是：根据给定的虚拟地址（VA），在三级页表中逐级向下查找，最终返回指向最低一级（L0）PTE 的指针。

它包含一个关键参数 `alloc`：
*   当 `alloc = 0` 时，`walk()` 只进行查找。如果中间某一级页表不存在，它会立刻返回 `NULL`。
*   当 `alloc = 1` 时，`walk()` 在查找过程中如果发现中间页表不存在，它会主动调用 `kalloc()` 分配一个新的物理页作为下一级页表，并将其链接到当前页表中。

这个“按需分配”的设计，使得我们可以用非常简洁的代码来创建页表映射。

#### 2.2.2. 页面映射 `mappages()`

`mappages()` 负责建立虚拟地址到物理地址的映射。它在一个循环中工作，以页为单位，为指定范围内的每一个虚拟地址：

1.  调用 `walk(va, 1)` 来获取其最终 PTE 的地址（如果不存在中间页表，`walk` 会自动创建）。
2.  检查该 PTE 是否已被使用。
3.  根据传入的物理地址（PA）和权限位（`perm`）构建一个新的 PTE，并写入 `walk` 返回的地址中。

这个函数是上层功能（如内核映射、用户空间分配）的直接构建者。

#### 2.2.3. 内核页表的建立

内核页表的初始化分为两步，由 `kvminit()` 和 `kvminithart()` 完成：
1.  **`kvminit()`**: 负责在内存中**构建**内核页表。它首先分配一个根页表页，然后调用 `kvmmap()`（`mappages`的封装）来建立关键的映射关系，包括：
    *   **硬件设备映射**：如 UART，将其物理地址直接映射到虚拟地址，方便内核读写。
    *   **内核内存映射**：将内核所在的物理地址区域（从 `KERNBASE` 到 `PHYSTOP`）进行等值映射（VA=PA），并赋予读、写、执行权限。
2.  **`kvminithart()`**: 负责**激活**页表。它将 `kvminit()` 创建的根页表的物理地址写入 `satp` 寄存器。一旦 `satp` 被写入，CPU 的 MMU（内存管理单元）就会立刻开始使用这个页表进行地址翻译。随后刷新 TLB 缓存，确保所有地址翻译都使用最新的页表。

#### 2.2.4. 页面回收与销毁

`unmap_pages()` 和 `freevm()` 负责内存的回收。

*   `unmap_pages()`：解除一段虚拟地址的映射，并**释放其背后对应的物理数据页**。
*   `freevm()`：通过递归函数 `free_pagetable_recursive()`，**只释放组成页表本身的那些物理页**，而不再关心它们指向的数据页。这种职责分离的设计使得内存管理逻辑更加清晰和健壮。

## 3. 调试历程：一次深刻的寻 Bug 之旅

在实现过程中，我们遇到了一个极其隐蔽且典型的 Bug，其调试过程值得详细记录。

### 3.1. 问题的初现

`test_virtual_memory` 测试失败。`print_pagetable` 的输出显示，本应将 `VA=0x80000000` 映射到 `PA=0x80000000` 的PTE，却错误地映射到了一个看似随机的物理地址，且权限位不正确（只有 `V` 有效）。

~~~
=== test_physical_memory ===
physical allocator test OK
=== test_pagetable ===
pagetable test OK
=== test_virtual_memory ===
Before kvminit, kernel_pagetable = 0x0
[kvminit] new kernel_pagetable = 0x87fff000
[kvminit] map UART0: VA=0x10000000 -> PA=0x10000000 size=0x1000 flags=RW
[kvminit] map kernel mem: VA=[0x80000000,0x88000000) -> PA=[0x80000000,0x88000000) flags=RWX
[kvminit] all mappings done.
After kvminit, kernel_pagetable = 0x87fff000
debug: pte for va 0x80000000 => raw=0x21fff801, pa=0x87ffe000, flags=0x1
kvminithart done. (paging enabled on this hart)
Read at KERNBASE succeeded (0x6f01011300001117)
virtual memory activation test OK
=== print_pagetable root=0x87fff000 ===
RAW PTE: 0x21fff401  NODE : VA range 0x0 - 0x3fffffff -> child PA 0x87ffd000
RAW PTE: 0x21fff001  NODE : VA range 0x10000000 - 0x101fffff -> child PA 0x87ffc000
LEAF: VA 0x10000000 - 0x10000fff => PA 0x10000000 size 0x1000 flags: VRW-----
RAW PTE: 0x21fff801  NODE : VA range 0x80000000 - 0xbfffffff -> child PA 0x87ffe000
RAW PTE: 0x21fff801  NODE : VA range 0x80000000 - 0x801fffff -> child PA 0x87ffe000
LEAF: VA 0x80000000 - 0x80000fff => PA 0x87ffe000 size 0x1000 flags: V-------
=== end print_pagetable ===
~~~

### 3.2. 推理与排查

1.  **初步怀疑**：`walk()` 或 `mappages()` 的逻辑有误。但经过代码审查，其逻辑是标准的，不像问题所在。
2.  **深入分析**：通过在 `kvminit` 中添加日志，我们发现 `kalloc()` 在为页表分配页时，连续两次返回了同一个物理页地址。这直接导致了 L1 页表中的一个PTE错误地指向了 L1 页表自身，造成了后续的映射错误。问题被锁定在物理内存分配器 `kalloc()` 的行为异常上。
3.  **寻找根源**：`kalloc()` 的行为异常，意味着 `freelist` 链表本身遭到了破坏。我们曾怀疑：
    *   **内存布局冲突**：内核栈与 `kinit` 管理的空闲内存区域重叠。我们通过修改链接器脚本，显式地为栈分配空间，并打印地址进行验证，排除了这个经典错误。
    *   **并发问题**：虽然系统是单核，但我们还是审查了 `kalloc` 的加锁逻辑，并将其中的 `memset` 移入锁内，使其在多核环境下是安全的。但这并未解决当前问题。
4.  **决定性的证据**：我们在 `kalloc` 中添加了调试打印，追踪每一次分配的页地址和下一个空闲页的地址。日志清晰地显示：在 `test_pagetable` 执行完毕后，`freelist` 变成了一个指向自身的死循环！

### 3.3. 真相大白：重复释放 (Double Free)

最终，我们在 `test_pagetable` 函数的清理代码中找到了罪魁祸首：
```c
/* cleanup */
unmap_pages(pt, va, PGSIZE); // 内部已经调用 kfree(p) 释放了数据页
kfree(p);                    // 这里又一次释放了同一个数据页 p！
freevm(pt, PGSIZE);
```
这个**重复释放**操作，导致 `kfree()` 第二次执行时，将 `freelist` 的头节点 `p` 的 `next` 指针设置成了它自己 (`p->next = p`)，从而制造了一个完美的死循环，污染了整个物理内存池。

在移除了多余的 `kfree(p)` 调用后，所有测试顺利通过，`print_pagetable` 打印出了数万行正确的内核映射关系，系统恢复正常。

## 4. 结果与总结

通过本次实现与调试，我们成功构建了一套功能正确的内存管理系统。最终的 `print_pagetable` 输出（如下图所示）展示了内核 128MB 内存空间被完整且正确地映射，证明了系统的稳定性。

1.  **内存管理，细节是魔鬼**：一个看似微不足道的重复释放，就能引发整个虚拟内存系统的崩溃。对内存生命周期的管理必须极其精确。
2.  **Bug 的表象具有欺骗性**：问题的症状（页表映射错误）与其根源（物理内存链表损坏）相去甚远。操作系统调试需要层层深入的逻辑推理能力。
3.  **调试打印是“银弹”**：在没有复杂调试工具的早期内核开发中，通过在关键路径上 **strategically** 地添加 `printf`，是观察系统内部状态、找到问题根源最有效的方法。

目前，本系统已为后续的用户进程隔离、`fork()` 等高级功能的实现铺平了道路。
